{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "batchsize = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(tf.float32, shape = (batchsize, 3))\n",
    "y_target = tf.placeholder(tf.float32)\n",
    "x_vals = np.array([[0,0], [0,1], [1,0], [1,1]]*10)\n",
    "y_vals = np.array([0, 0, 0, 1]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 3)\n"
     ]
    }
   ],
   "source": [
    "b = np.ones(x_vals.shape[0]).reshape(-1,1)\n",
    "x_vals = np.column_stack([b, x_vals])\n",
    "print(x_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal(shape=[3]))\n",
    "output = tf.tensordot(x_data , w, axes = 1)\n",
    "loss = (output - y_target) ** 2. / 2.\n",
    "delta_loss = tf.reduce_mean( tf.tensordot(tf.diag(y_target - output), (-x_data), 1), axis = 0) + 0.1 * w * w\n",
    "learning_rate =0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = tf.reduce_mean(tf.tensordot(x_data , w, axes = 1) )\n",
    "#output = x_data * tf.ones(3)\n",
    "#print(sess.run(output, feed_dict={x_data:x_vals[:5]}) )\n",
    "#abs_vals = y_target - output\n",
    "#delta_loss = tf.reduce_mean( tf.tensordot(tf.diag(y_target - output), (-x_data), 1), axis = 0)+ 0.1 * w * w\n",
    "#print(sess.run(delta_loss, feed_dict={x_data: x_vals[:5], y_target: y_vals[:5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.initialize_all_variables\n",
    "\n",
    "#merged = tf.summary.merge_all()\n",
    "#writer = tf.summary.FileWriter('f:/tensorboard_logs', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Optimizer\n",
    "#my_opt = tf.train.batch()\n",
    "#train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 19 38]\n"
     ]
    }
   ],
   "source": [
    "index = np.arange(x_vals.shape[0])\n",
    "print(np.random.choice(index, size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "Step #1w = [ 0.03013145 -0.35157439 -0.01612163] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #2w = [ 0.03007706 -0.35162511 -0.01615542] Loss = 0.000363601\n",
      "(4, 3)\n",
      "Step #3w = [ 0.0302034  -0.35150197 -0.01605545] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #4w = [ 0.03024377 -0.35146174 -0.01602235] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #5w = [ 0.03032608 -0.35138127 -0.01598752] Loss = 0.249639\n",
      "(4, 3)\n",
      "Step #6w = [ 0.03047694 -0.35122874 -0.01575552] Loss = 0.447494\n",
      "(4, 3)\n",
      "Step #7w = [ 0.03012836 -0.35157511 -0.01615961] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #8w = [ 0.03047236 -0.35123643 -0.0158872 ] Loss = 0.249639\n",
      "(4, 3)\n",
      "Step #9w = [ 0.03014152 -0.35156152 -0.01616101] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #10w = [ 0.03048198 -0.35122034 -0.01582032] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #11w = [ 0.03015023 -0.35154793 -0.01615857] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #12w = [ 0.03056191 -0.35113987 -0.01575344] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #13w = [ 0.03016784 -0.35153434 -0.0161638 ] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #14w = [ 0.03029185 -0.35141489 -0.01615962] Loss = 0.0259844\n",
      "(4, 3)\n",
      "Step #15w = [ 0.03030681 -0.35140005 -0.01615997] Loss = 0.0259844\n",
      "(4, 3)\n",
      "Step #16w = [ 0.03073469 -0.35097894 -0.01563083] Loss = 0.236651\n",
      "(4, 3)\n",
      "Step #17w = [ 0.0307686  -0.35093871 -0.01559216] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #18w = [ 0.03096722 -0.35075364 -0.01555907] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #19w = [ 0.03035901 -0.35134068 -0.01615476] Loss = 0.0260733\n",
      "(4, 3)\n",
      "Step #20w = [ 0.030722   -0.35097834 -0.01549985] Loss = 0.22384\n",
      "(4, 3)\n",
      "Step #21w = [ 0.03092163 -0.35077778 -0.01545248] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #22w = [ 0.03152934 -0.35017827 -0.01469098] Loss = 0.447494\n",
      "(4, 3)\n",
      "Step #23w = [ 0.03101082 -0.35069731 -0.01539361] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #24w = [ 0.03045123 -0.35126647 -0.01617149] Loss = 0.0258955\n",
      "(4, 3)\n",
      "Step #25w = [ 0.03131136 -0.35041568 -0.01532743] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #26w = [ 0.03025339 -0.351446   -0.01617288] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #27w = [ 0.0316361  -0.35010186 -0.01525184] Loss = 0.262449\n",
      "(4, 3)\n",
      "Step #28w = [ 0.03025523 -0.35143241 -0.01616453] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #29w = [ 0.03026141 -0.35142562 -0.01616488] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #30w = [ 0.03231926 -0.34941164 -0.01415871] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #31w = [ 0.03108637 -0.35062397 -0.01515047] Loss = 0.223751\n",
      "(4, 3)\n",
      "Step #32w = [ 0.03192384 -0.34982023 -0.01508464] Loss = 0.262449\n",
      "(4, 3)\n",
      "Step #33w = [ 0.03113781 -0.35055953 -0.01507419] Loss = 0.22384\n",
      "(4, 3)\n",
      "Step #34w = [ 0.0323324  -0.34939042 -0.01390442] Loss = 0.447406\n",
      "(4, 3)\n",
      "Step #35w = [ 0.0323844  -0.34932476 -0.01382604] Loss = 0.447494\n",
      "(4, 3)\n",
      "Step #36w = [ 0.03185214 -0.3498846  -0.01496342] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #37w = [ 0.03032578 -0.35137126 -0.01618057] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #38w = [ 0.03291578 -0.34882203 -0.01362644] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #39w = [ 0.03131395 -0.35036623 -0.01486414] Loss = 0.223929\n",
      "(4, 3)\n",
      "Step #40w = [ 0.03171332 -0.35001335 -0.01484498] Loss = 0.236651\n",
      "(4, 3)\n",
      "Step #41w = [ 0.03313947 -0.34860092 -0.01342684] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #42w = [ 0.03177787 -0.34993288 -0.01476487] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #43w = [ 0.03000468 -0.35167521 -0.01619973] Loss = 0.000185859\n",
      "(4, 3)\n",
      "Step #44w = [ 0.03334546 -0.34837982 -0.01321191] Loss = 0.460394\n",
      "(4, 3)\n",
      "Step #45w = [ 0.03267197 -0.34908798 -0.01464992] Loss = 0.262449\n",
      "(4, 3)\n",
      "Step #46w = [ 0.03156098 -0.35020104 -0.01615481] Loss = 0.0516941\n",
      "(4, 3)\n",
      "Step #47w = [ 0.03358687 -0.34815872 -0.01302764] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #48w = [ 0.03078136 -0.35091028 -0.01615481] Loss = 0.0260733\n",
      "(4, 3)\n",
      "Step #49w = [ 0.03081573 -0.35089543 -0.01617188] Loss = 0.0259844\n",
      "(4, 3)\n",
      "Step #50w = [ 0.03339128 -0.34833995 -0.01284545] Loss = 0.447406\n",
      "(4, 3)\n",
      "Step #51w = [ 0.03216187 -0.34957078 -0.01448481] Loss = 0.236651\n",
      "(4, 3)\n",
      "Step #52w = [ 0.03040347 -0.35126933 -0.01617293] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #53w = [ 0.03268791 -0.34906384 -0.01440086] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #54w = [ 0.029963   -0.35168865 -0.01619244] Loss = 0.00027473\n",
      "(4, 3)\n",
      "Step #55w = [ 0.03090554 -0.35080639 -0.01617398] Loss = 0.0259844\n",
      "(4, 3)\n",
      "Step #56w = [ 0.03045081 -0.35124215 -0.01619384] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #57w = [ 0.03043435 -0.35123536 -0.01617468] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #58w = [ 0.0324473  -0.34928915 -0.0142556 ] Loss = 0.236651\n",
      "(4, 3)\n",
      "Step #59w = [ 0.03094157 -0.35074702 -0.01615483] Loss = 0.0260733\n",
      "(4, 3)\n",
      "Step #60w = [ 0.03402875 -0.3476834  -0.0121627 ] Loss = 0.447494\n",
      "(4, 3)\n",
      "Step #61w = [ 0.03308121 -0.34867761 -0.01413612] Loss = 0.24955\n",
      "(4, 3)\n",
      "Step #62w = [ 0.03204028 -0.34962526 -0.01410303] Loss = 0.223929\n",
      "(4, 3)\n",
      "Step #63w = [ 0.03477991 -0.3469795  -0.0119631 ] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #64w = [ 0.0343178  -0.34742078 -0.01191886] Loss = 0.447406\n",
      "(4, 3)\n",
      "Step #65w = [ 0.03213501 -0.34952861 -0.01400376] Loss = 0.223929\n",
      "(4, 3)\n",
      "Step #66w = [ 0.03555709 -0.34622929 -0.01174051] Loss = 0.473204\n",
      "(4, 3)\n",
      "Step #67w = [ 0.03049612 -0.35116741 -0.01617818] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #68w = [ 0.03455494 -0.34715816 -0.01163043] Loss = 0.447494\n",
      "(4, 3)\n",
      "Step #69w = [ 0.0311151  -0.3505986  -0.01617888] Loss = 0.0259844\n",
      "(4, 3)\n",
      "Step #70w = [ 0.0334953  -0.34824309 -0.01381392] Loss = 0.249639\n",
      "(4, 3)\n",
      "Step #71w = [ 0.03235325 -0.34933531 -0.01382994] Loss = 0.22384\n",
      "(4, 3)\n",
      "Step #72w = [ 0.03296003 -0.34872589 -0.01374704] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #73w = [ 0.033      -0.34868565 -0.0137136 ] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #74w = [ 0.03306974 -0.34864542 -0.01370593] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #75w = [ 0.03307994 -0.34860519 -0.01364672] Loss = 0.236828\n",
      "(4, 3)\n",
      "Step #76w = [ 0.03055171 -0.35110626 -0.01618133] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #77w = [ 0.0305269  -0.35109946 -0.01615486] Loss = 0.0132629\n",
      "(4, 3)\n",
      "Step #78w = [ 0.03254554 -0.3491098  -0.01357356] Loss = 0.223929\n",
      "(4, 3)\n",
      "Step #79w = [ 0.03794799 -0.34379435 -0.00822906] Loss = 0.671149\n",
      "(4, 3)\n",
      "Step #80w = [ 0.0333444  -0.34840402 -0.01353525] Loss = 0.236651\n",
      "(4, 3)\n",
      "Step #81w = [ 0.02996868 -0.35172164 -0.01626773] Loss = 9.69886e-05\n",
      "(4, 3)\n",
      "Step #82w = [ 0.03134282 -0.35040566 -0.016212  ] Loss = 0.0258955\n",
      "(4, 3)\n",
      "Step #83w = [ 0.03623782 -0.34550548 -0.01060352] Loss = 0.460394\n",
      "(4, 3)\n",
      "Step #84w = [ 0.03063507 -0.3510519  -0.01621339] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #85w = [ 0.03642035 -0.34535807 -0.01049936] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #86w = [ 0.03064823 -0.35103831 -0.01621479] Loss = 0.0130851\n",
      "(4, 3)\n",
      "Step #87w = [ 0.03656948 -0.34521067 -0.01036629] Loss = 0.460305\n",
      "(4, 3)\n",
      "Step #88w = [ 0.03062583 -0.35102472 -0.01618554] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #89w = [ 0.03367531 -0.34804192 -0.01320956] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #90w = [ 0.02995606 -0.35173264 -0.01628028] Loss = 9.69886e-05\n",
      "(4, 3)\n",
      "Step #91w = [ 0.03224435 -0.34953985 -0.01618659] Loss = 0.0387948\n",
      "(4, 3)\n",
      "Step #92w = [ 0.03690529 -0.34484217 -0.01000158] Loss = 0.460394\n",
      "(4, 3)\n",
      "Step #93w = [ 0.03697946 -0.34476846 -0.0099347 ] Loss = 0.460394\n",
      "(4, 3)\n",
      "Step #94w = [ 0.0402679  -0.34155157 -0.00672419] Loss = 0.683959\n",
      "(4, 3)\n",
      "Step #95w = [ 0.02991083 -0.35173875 -0.01625417] Loss = 0.000185859\n",
      "(4, 3)\n",
      "Step #96w = [ 0.03315288 -0.34852991 -0.01301135] Loss = 0.22384\n",
      "(4, 3)\n",
      "Step #97w = [ 0.03642332 -0.34525418 -0.00966717] Loss = 0.447583\n",
      "(4, 3)\n",
      "Step #98w = [ 0.03403865 -0.34767982 -0.01291173] Loss = 0.236739\n",
      "(4, 3)\n",
      "Step #99w = [ 0.03069377 -0.35094997 -0.01618939] Loss = 0.013174\n",
      "(4, 3)\n",
      "Step #100w = [ 0.03328082 -0.34840104 -0.01288038] Loss = 0.22384\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    rand_index = np.random.choice(index, size=batchsize)\n",
    "    rand_x = x_vals[rand_index]\n",
    "    rand_y = y_vals[rand_index]\n",
    "    print(rand_x.shape)\n",
    "    w = w - learning_rate * delta_loss\n",
    "    w_vals = sess.run(w, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    print('Step #' + str(i+1) + 'w = '+ str(w_vals), end = ' ')\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "    print('Loss = ' + str(sess.run(loss_mean,feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
